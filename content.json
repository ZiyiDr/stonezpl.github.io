{"pages":[{"title":"categories","text":"","link":"/categories/index.html"},{"title":"tags","text":"#ddd","link":"/tags/index.html"},{"title":"关于作者","text":"简介本博客主要维护人张珮磊(别问我静静是谁，我只是想而已)，毕业于重庆邮电大学计算机专业 初衷代码写多了，总会感到技术有种小小的无奈，但希望技术能够给生活带去一点点美好 联系方式微信: zplxjj 公众号:stonezplxjj","link":"/about/index.html"}],"posts":[{"title":"linux 常用命令(持续更新)","text":"查看磁盘空间大小 查看磁盘空间大小: df -h 查看指定目录大小: du -sh &lt;目录名&gt; du -h [目录名]：查看指定文件夹下的所有文件大小（包含子文件夹) 对文件大小进行排序(进入当前目录下)： 文本查询相关 统计某个词出现频率 统计单词次数并按次数排序(每一行为一个单词): 按照分隔符分词，然后排序，去重： 查看端口占用 查看端口占用进程和进程占用端口 mac下根据进程id查看端口占用1lsof -n -P | grep 27825 给用户授权可查看目录权限1sudo chown -R zhangpeilei /Users/zhangpeilei/local/elasticsearch-7.2.0","link":"/2019/04/01/linux/"},{"title":"redis分布式锁——简单实现","text":"前言最近项目当中需要处理分布式系统中的并发问题，自然地想到了引入分布式锁，本文旨在讲述用redis简单的实现分布式锁，对于复杂的类似于redis集群问题、为什么不用zk等，自己也在学习，希望可以以后有机会分享 分布式锁的可靠性保证 在过期时间内，只有一个客户端持有锁 在客户端持有锁期间短暂崩溃或者redis发生短暂崩溃时，不会有死锁状态 加锁和解锁必须是同一客户端，加锁和解锁必须是同一个客户端 代码实现 项目当中的实现12345678910111213141516171819202122232425262728293031323334353637383940414243public static Boolean lock(String key) { Long nowTIme = System.nanoTime(); //TIMEOUT_NANO：超时时间 while (TIMEOUT_NANO &gt; System.nanoTime() - nowTIme) { long expires = System.nanoTime() + EXPIRE_NANO; //锁到期时间 String expiresStr = String.valueOf(expires); //putIfAbsent: setnx命令 if (putIfAbsent(key, expiresStr)) { return true; } //当redis存在这个key的时候，取出这个key，判断是否超时 String currentValue = get(key); //判断锁是否已经过期，过期则重新设置并获取 if (currentValue != null) { if(Long.parseLong(currentValue) &lt; System.nanoTime() - EXPIRE_NANO){ //设置锁并返回旧值：getSet String oldValue = getAndSet(key, expiresStr); //比较锁的时间，如果不一致则可能是其他锁已经修改了值并获取 if (oldValue != null &amp;&amp; oldValue.equals(currentValue)) { return true; } }else { return false; } } } throw new RuntimeException(\"get redis lock timeout,key=[\" + key + \"]\");}public static Boolean unlock(String key) { if (StringUtils.isBlank(key)) { return false; } try { //redis的del命令 del(key); } catch (Exception e) { log.error(\"redis unlock exception, key={}\", key, e); return false; } return true;} 项目中代码存在的问题 过期时间调用的是: System.nanoTime(),这就需要客户端的时间必须同步 getAndSet 虽然只有一个客户端可以获取锁，但是会覆盖过期时间 锁不具备拥有者标识，相当于所有客户端都拥有相同的key，且对应的value区分不出客户端，即任何客户端都可以解锁。举例：客户端A加锁，一段时间之后客户端A解锁，在执行删除key之前，锁突然过期了，此时客户端B尝试加锁成功，然后客户端A再执行del()方法，则将客户端B的锁给解除了。 加锁过程优化 加锁原理：基于redis的set命令，value为每个客户端唯一的id，10000为过期时间，相当于setex和setnx两条命令的整合 解锁原理(摘抄网上一段方法)123456789//eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令,保证了其原子性public static boolean del(Jedis jedis, String key, String requestId) { String script = \"if redis.call('get', KEYS[1]) == ARGV[1] then return redis.call('del', KEYS[1]) else return 0 end\"; Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); if (RELEASE_SUCCESS.equals(result)) { return true; } return false; }","link":"/2019/04/03/redis/"},{"title":"springboot(一)——搭建属于自己的springboot项目","text":"idea使用spring Initalizr 快速构建spring boot 点击新建项目,选择如图所示 点击next后 点击next，之后按照图中所示选择 选择路径 点击完成，如图所示，删除自己不想要的，项目构建完成 构建一个controller，启动项目就可以看到返回结果了 在自己的服务器搭建自己的springboot项目使用idea向远程服务传递项目 设置idea 配置相关信息 上传到指定机器 配置启动脚本，基于java -jar命令 start.sh 12#!/bin/bashnohup java -jar target/zplxjj.jar &amp; stop.sh 12345678910#!/bin/bashPID=$(ps -ef | grep target/zplxjj.jar | grep -v grep | awk &apos;{ print $2 }&apos;)if [ -z &quot;$PID&quot; ]then echo Application is already stoppedelse echo kill $PID kill $PIDfi~ run.sh 12345#!/bin/bashecho stop applicationsource stop.shecho start applicationsource start.sh 启动自己的项目只需要执行run.sh就行，一个自己的spring boot就搭建起来了 logback配置实际项目中，我们希望日志可以记录在服务器上面，这边用的是logback，是springboot自带的，我这边集成方式是加入logback-spring.xml文件，加入后启动项目即可，文件内容如下：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;configuration&gt; &lt;!--用来定义变量值的标签--&gt; &lt;property name=\"LOG_HOME\" value=\"./logs\"/&gt; &lt;property name=\"encoding\" value=\"UTF-8\"/&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度；%M:%L是方法和行号；%msg是日志消息；%n是换行符--&gt; &lt;property name=\"normal-pattern\" value=\"%d{yyyy-MM-dd/HH:mm:ss.SSS}|%X{localIp}|%X{requestId}|%X{requestSeq}|%X{country}|%X{deviceType}|%X{deviceId}|%X{userId}|^_^|[%t] %-5level %logger{50} %line - %m%n\"/&gt; &lt;property name=\"plain-pattern\" value=\"%d{yyyy-MM-dd.HH:mm:ss} %msg%n\"/&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name=\"FILE\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;file&gt;${LOG_HOME}/zplxjj.log&lt;/file&gt; &lt;Append&gt;true&lt;/Append&gt; &lt;prudent&gt;false&lt;/prudent&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;pattern&gt;${normal-pattern}&lt;/pattern&gt; &lt;charset&gt;${encoding}&lt;/charset&gt; &lt;/encoder&gt; &lt;!--按时间分割--&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${LOG_HOME}/zplxjj.log.%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt; &lt;maxFileSize&gt;128MB&lt;/maxFileSize&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;totalSizeCap&gt;32GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!--控制台输出--&gt; &lt;appender name=\"STDOUT\" class=\"ch.qos.logback.core.ConsoleAppender\"&gt; &lt;encoder class=\"ch.qos.logback.classic.encoder.PatternLayoutEncoder\"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;${normal-pattern}&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- log file error --&gt; &lt;appender name=\"ERROR\" class=\"ch.qos.logback.core.rolling.RollingFileAppender\"&gt; &lt;filter class=\"ch.qos.logback.classic.filter.ThresholdFilter\"&gt; &lt;level&gt;ERROR&lt;/level&gt; &lt;/filter&gt; &lt;file&gt;${LOG_HOME}/zplxjj-error.log&lt;/file&gt; &lt;prudent&gt;false&lt;/prudent&gt; &lt;Append&gt;true&lt;/Append&gt; &lt;encoder&gt; &lt;pattern&gt;${normal-pattern}&lt;/pattern&gt; &lt;charset&gt;${encoding}&lt;/charset&gt; &lt;/encoder&gt; &lt;rollingPolicy class=\"ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy\"&gt; &lt;fileNamePattern&gt;${LOG_HOME}/zplxjj-error.log.%d{yyyy-MM-dd}.%i&lt;/fileNamePattern&gt; &lt;maxFileSize&gt;128MB&lt;/maxFileSize&gt; &lt;maxHistory&gt;15&lt;/maxHistory&gt; &lt;totalSizeCap&gt;32GB&lt;/totalSizeCap&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;root level=\"INFO\"&gt; &lt;appender-ref ref=\"STDOUT\"/&gt; &lt;appender-ref ref=\"FILE\"/&gt; &lt;appender-ref ref=\"ERROR\"/&gt; &lt;/root&gt;&lt;/configuration&gt; 效果如图：","link":"/2019/04/16/springboot/"},{"title":"springboot(四)——@EnableConfigurationProperties是如何起作用的你知道吗","text":"前言用springboot开发的过程中，我们会用到@ConfigurationProperties注解，主要是用来把properties或者yml配置文件转化为bean来使用的，而@EnableConfigurationProperties注解的作用是@ConfigurationProperties注解生效。如果只配置@ConfigurationProperties注解，在IOC容器中是获取不到properties配置文件转化的bean的，当然在@ConfigurationProperties加入注解的类上加@Component也可以使交于springboot管理。 举个栗子 第一步：创建一个类TestConfigurationProperties123456789101112@ConfigurationProperties(prefix = \"properties\")public class TestConfigurationProperties { private String name; public String getName() { return name; } public void setName(String name) { this.name = name; }} 注意：得加上set和get方法第二步：创建TestAutoConfiguration类1234567891011121314151617@Configuration@EnableConfigurationProperties(TestConfigurationProperties.class)public class TestAutoConfiguration { private TestConfigurationProperties testConfigurationProperties; public TestAutoConfiguration(TestConfigurationProperties testConfigurationProperties) { this.testConfigurationProperties = testConfigurationProperties; } @Bean public User user(){ User user = new User(); user.setName(testConfigurationProperties.getName()); return user; }} 注意：得创建一个有参构造方法第三步：配置文件加入属性1properties.name=test 第四步：跑一下，打印出User这个类1234567891011121314151617@RestController@RequestMapping(\"/api/test\")@Slf4jpublic class TestController { @Autowired TestConfigurationProperties testConfigurationProperties; @Autowired User user; @RequestMapping(value = \"/testConfigurationProperties\") public String testConfigurationProperties() { log.info(\"test testConfigurationProperties.............{}\", testConfigurationProperties.getName()); log.info(\"user:{}\", user); return \"SUCCESS\"; }} 控制台输出：122019-04-21/16:11:36.638||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.controller.TestController 37 - test testConfigurationProperties.............test2019-04-21/16:11:36.639||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.controller.TestController 38 - user:User(id=null, name=test) @EnableConfigurationProperties是怎么加载的通过查看@EnableConfigurationProperties的注解：1234567891011121314@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Import(EnableConfigurationPropertiesImportSelector.class)public @interface EnableConfigurationProperties { /** * Convenient way to quickly register {@link ConfigurationProperties} annotated beans * with Spring. Standard Spring Beans will also be scanned regardless of this value. * @return {@link ConfigurationProperties} annotated beans to register */ Class&lt;?&gt;[] value() default {};} 通过分析自动配置可以知道，肯定是这个类EnableConfigurationPropertiesImportSelector起的作用：12345678private static final String[] IMPORTS = { ConfigurationPropertiesBeanRegistrar.class.getName(), ConfigurationPropertiesBindingPostProcessorRegistrar.class.getName() }; @Override public String[] selectImports(AnnotationMetadata metadata) { return IMPORTS; } selectImports方法返回了这两个类：ConfigurationPropertiesBeanRegistrar和ConfigurationPropertiesBindingPostProcessorRegistrar，是何时加载的，我们只需要看这个类ConfigurationPropertiesBeanRegistrar即可：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public static class ConfigurationPropertiesBeanRegistrar implements ImportBeanDefinitionRegistrar { @Override public void registerBeanDefinitions(AnnotationMetadata metadata, BeanDefinitionRegistry registry) { getTypes(metadata).forEach((type) -&gt; register(registry, (ConfigurableListableBeanFactory) registry, type)); } //找到加入这个注解@EnableConfigurationProperties里面的value值，其实就是类class private List&lt;Class&lt;?&gt;&gt; getTypes(AnnotationMetadata metadata) { MultiValueMap&lt;String, Object&gt; attributes = metadata .getAllAnnotationAttributes( EnableConfigurationProperties.class.getName(), false); return collectClasses((attributes != null) ? attributes.get(\"value\") : Collections.emptyList()); } private List&lt;Class&lt;?&gt;&gt; collectClasses(List&lt;?&gt; values) { return values.stream().flatMap((value) -&gt; Arrays.stream((Object[]) value)) .map((o) -&gt; (Class&lt;?&gt;) o).filter((type) -&gt; void.class != type) .collect(Collectors.toList()); } //注册方法：根据找到的类名name和type，将加入注解@ConfigurationProperties的类加入spring容器里面 private void register(BeanDefinitionRegistry registry, ConfigurableListableBeanFactory beanFactory, Class&lt;?&gt; type) { String name = getName(type); if (!containsBeanDefinition(beanFactory, name)) { registerBeanDefinition(registry, name, type); } } //找到加入注解@ConfigurationProperties的类的名称，加入一定格式的拼接 private String getName(Class&lt;?&gt; type) { ConfigurationProperties annotation = AnnotationUtils.findAnnotation(type, ConfigurationProperties.class); String prefix = (annotation != null) ? annotation.prefix() : \"\"; return (StringUtils.hasText(prefix) ? prefix + \"-\" + type.getName() : type.getName()); } private boolean containsBeanDefinition( ConfigurableListableBeanFactory beanFactory, String name) { if (beanFactory.containsBeanDefinition(name)) { return true; } BeanFactory parent = beanFactory.getParentBeanFactory(); if (parent instanceof ConfigurableListableBeanFactory) { return containsBeanDefinition((ConfigurableListableBeanFactory) parent, name); } return false; } private void registerBeanDefinition(BeanDefinitionRegistry registry, String name, Class&lt;?&gt; type) { assertHasAnnotation(type); GenericBeanDefinition definition = new GenericBeanDefinition(); definition.setBeanClass(type); registry.registerBeanDefinition(name, definition); } private void assertHasAnnotation(Class&lt;?&gt; type) { Assert.notNull( AnnotationUtils.findAnnotation(type, ConfigurationProperties.class), () -&gt; \"No \" + ConfigurationProperties.class.getSimpleName() + \" annotation found on '\" + type.getName() + \"'.\"); } } 结语另外还有这个类：ConfigurationPropertiesBindingPostProcessorRegistrar，刚刚没有分析，看了下源码，其实他做的事情就是将配置文件当中的属性值赋予到加了@ConfigurationProperties的注解的类的属性上，具体就不分析了，有兴趣自己可以阅读，入口知道了，就简单了","link":"/2019/04/24/springboot-2/"},{"title":"与go邂逅(一)——go环境搭建和Helloworld(开发工具：GOLAND)","text":"环境搭建学习语言，搭建环境必不可少，虽然网上教程也很多，但是我也记录下我的mac上面环境配置 从网上下载安装文件，下载地址：https://golang.google.cn/dl/ mac 有自带的pkg文件，但是我选择的是go1.12.4.darwin-amd64.tar.gz 下载下来解压即可，会有个命名为go的文件夹 配置环境变量，修改/etc/profile(全局的)或者.bash_profile(私有的)即可，配置完执行下source，我的配置如下：123export GOROOT=$HOME/go_dev/goexport PATH=$PATH:$GOROOT/binexport GOPATH=$HOME/code/personal/code/go_project 配置完，执行go version查看安装是否成功 开发工具没有做过比较，只是之前写java的时候用的idea，所以用了goland，它们都是一家公司的，挺好用 创建项目 新建一个项目，配置好路径2如图所以创建三个目录创建以.go为结尾的文件，命名随意写一个hello world 执行下:1234567package mainimport \"fmt\"func main(){ fmt.Println(\"Hello World\")} 写到这里，其实go语言环境就跑通了，其实我们在写java项目的时候，都会有单元测试类，其实go当中也有，只要遵循一定的写法就可以了，我们首先见一个目录：文件名称需要以_test结尾，代码如下：12345678package testimport \"testing\"//方法名以Test开头，加入参数，*testing.T tfunc TestPrint(t *testing.T) { t.Log(\"test hello world\")}","link":"/2019/04/25/与go邂逅/"},{"title":"与go邂逅(二)——基本程序结构","text":"前言学习一门语言的时候，难免从最简单的程序结构学起，这些东西在掌握了一门别的开发语言的情况(如大名鼎鼎的java)，就会显得如鱼得水了，下面会把我学习一些简单例子分享出来。 基本程序结构快速为一些变量赋值1234567891011const ( NUM1 = 1 + iota NUM2 NUM3 NUM4)//输出结果：1，2，4，8func TestPrint(t *testing.T) { t.Log(NUM1, NUM2, NUM3, NUM4)} 快速的实现一些数值交换12345678910//数值交换func TestExchange(t *testing.T) {//也可以这样定义变量：var aa int = 1 a := 1 b := 2 t.Log(a, b) //交换数值 b, a = a, b t.Log(a, b)} 类型转换123456789101112//给类型命名type typeInt int64func TestInt(t *testing.T) { var a int64 = 2 var b int32 = 3 //类型不可转 //a = b var c = typeInt(3) t.Log(a, b, c)} 实现斐波拉切数列的两种方式123456789101112131415161718192021222324//斐波拉切func TestFibList(t *testing.T) { var a int = 1 var b int = 1 t.Log(a) for i := 0; i &lt; 5; i++ { t.Log(b) tmp := a + b a = b b = tmp }}//斐波拉切 递归func TestFibRecursion(t *testing.T) { t.Log(FibRecursion(5))}func FibRecursion(i int) (result int) { if i == 1 || i == 2 { return 1 } return FibRecursion(i-1) + FibRecursion(i-2)} 数组比较，和java不同，不是比较指针，可以比较值的12345678//数组比较func TestCompareArray(t *testing.T) { a := [...]int{1, 2, 3, 4} b := [...]int{1, 2, 2, 4} c := [...]int{1, 2, 3, 4} t.Log(a == b) //false t.Log(a == c) //true} go也是有指针的，但是没有细看，只是写个例子看下结果1234567func TestPoint(t *testing.T) { var a int64 = 1 var aPtr = &amp;a t.Log(a, aPtr)// 1 0xc420018230 //打印类: int64 *int64 t.Logf(\"%T %T\", a, aPtr)} string的默认值12345func TestString(t *testing.T) { //默认值是\"\" 不是java的那种null var str string t.Log(\"+\" + str + \"+\")//输出++} for循环12345678910111213141516171819202122232425//for循环 go当中原来没有whilefunc TestFor(t *testing.T) { n := 5 for n &gt; 0 { t.Log(n) n-- }}//for循环实现冒泡排序func TestForSort(t *testing.T) { a := [...]int{3, 5, 2, 6, 4, 8, 2, 9,1,23,2,34,4,55,11} for i := 0; i &lt; len(a)-1; i++ { for j := 0; j &lt; len(a)-i-1; j++ { if a[j] &gt; a[j+1] { tmp := a[j] a[j] = a[j+1] a[j+1] = tmp } } } t.Log(a)//[1 2 2 2 3 4 4 5 6 8 9 11 23 34 55]} go当中的条件判断，写起来还是很爽的1234567891011121314151617181920212223242526272829//比较func TestCondition(t *testing.T){ //可以条件结果赋值给变量 if a:=3&gt;2;a{ t.Log(\"3&gt;2\") } // GOOS is the running program's operating system target: // one of darwin, freebsd, linux, and so on. switch runtime.GOOS{ //自带break case \"darwin\": t.Log(\"darwin\") case \"freebsd\": t.Log(\"freebsd\") case \"linux\": t.Log(\"linux\") default: t.Log(\"default\") } switch { case 4&gt;2: t.Log(\"4&gt;2\") case 4&lt;2: t.Log(\"4&lt;2\") }} string的默认值12345func TestString(t *testing.T) { //默认值是\"\" 不是java的那种null var str string t.Log(\"+\" + str + \"+\")//输出++} for循环12345678910111213141516171819202122232425//for循环 go当中原来没有whilefunc TestFor(t *testing.T) { n := 5 for n &gt; 0 { t.Log(n) n-- }}//for循环实现冒泡排序func TestForSort(t *testing.T) { a := [...]int{3, 5, 2, 6, 4, 8, 2, 9,1,23,2,34,4,55,11} for i := 0; i &lt; len(a)-1; i++ { for j := 0; j &lt; len(a)-i-1; j++ { if a[j] &gt; a[j+1] { tmp := a[j] a[j] = a[j+1] a[j+1] = tmp } } } t.Log(a)//[1 2 2 2 3 4 4 5 6 8 9 11 23 34 55]} go当中的条件判断，写起来还是很爽的1234567891011121314151617181920212223242526272829//比较func TestCondition(t *testing.T){ //可以条件结果赋值给变量 if a:=3&gt;2;a{ t.Log(\"3&gt;2\") } // GOOS is the running program's operating system target: // one of darwin, freebsd, linux, and so on. switch runtime.GOOS{ //自带break case \"darwin\": t.Log(\"darwin\") case \"freebsd\": t.Log(\"freebsd\") case \"linux\": t.Log(\"linux\") default: t.Log(\"default\") } switch { case 4&gt;2: t.Log(\"4&gt;2\") case 4&lt;2: t.Log(\"4&lt;2\") }} string的基本操作123456789101112131415161718func TestString(t *testing.T) { //分割:[a b c] s := \"a,b,c\" splitStr := strings.Split(s, \",\") t.Log(splitStr) //拼接:a:b:c stringJoin := strings.Join(splitStr, \":\") t.Log(stringJoin) //整型转字符串 str := strconv.Itoa(10) t.Log(str) //字符串转整型 if i, e := strconv.Atoi(\"10\"); e == nil { t.Log(i) } map初始化123456789101112func TestInitMap(t *testing.T) { m1 := map[int]int{1: 2, 3: 4, 5: 6} t.Log(m1[2]) t.Logf(\"len m1=%d\", len(m1)) m2 := map[int]int{} m2[4] = 16 t.Logf(\"len m2=%d\", len(m2)) m3 := make(map[int]int, 10) t.Logf(\"len m3=%d\", len(m3))} map判断key是否存在和循环12345678910111213141516171819func TestExistKey(t *testing.T) { m1 := map[int]int{} t.Log(m1[1]) m1[2] = 0 t.Log(m1[2]) m1[3] = 0 if v, ok := m1[3]; ok { t.Logf(\"Key 3's value is %d\", v) } else { t.Log(\"key 3 is not existing.\") }}func TestForMap(t *testing.T) { m1 := map[int]int{1: 1, 2: 4, 3: 9} for k, v := range m1 { t.Log(k, v) }} map当中的工厂模式1234567func TestFunc(t *testing.T) { m := map[int]func(op int) int{} m[1] = func(op int) int { return op } m[2] = func(op int) int { return op * op } m[3] = func(op int) int { return op * op * op } t.Log(m[1](2), m[2](2), m[3](2))} map模拟一个set1234567891011121314151617181920func TestMapForSet(t *testing.T) { mySet := map[int]bool{} mySet[1] = true n := 3 //判断是否存在 if mySet[n] { t.Logf(\"%d is existing\", n) } else { t.Logf(\"%d is not existing\", n) } mySet[3] = true t.Log(len(mySet)) delete(mySet, 1) n = 1 if mySet[n] { t.Logf(\"%d is existing\", n) } else { t.Logf(\"%d is not existing\", n) }} 线程安全map123456789101112131415161718192021222324//store:存储一个设置的键值//LoadOrStore:返回键的现有值(如果存在)，否则存储并返回给定的值，如果是读取则返回true，如果是存储返回false//Load:读取存储在map中的值，如果没有值，则返回nil。OK的结果表示是否在map中找到值。func TestSyncMap(t *testing.T) { m := sync.Map{} v, ok := m.LoadOrStore(\"1\", \"one\") t.Log(v, ok) //one false v, ok = m.Load(\"2\") t.Log(v, ok) //nil false v, ok = m.LoadOrStore(\"1\", \"oneone\") t.Log(v, ok) //one true v, ok = m.Load(\"1\") t.Log(v, ok) //one true m.Store(\"1\", \"oneone\") v, ok = m.Load(\"1\") t.Log(v, ok) // oneone true }","link":"/2019/04/26/与go邂逅/"},{"title":"springboot(五)——springboot中的拦截器和过滤器小结","text":"前言关于过滤器Filter和拦截器Interceptor，大家都不会陌生，从一开始的servelet，到springmvc，再到现在的springboot，都有接触到，记得刚接触的时候，会容易弄混淆，想写这篇文章做个小的总结 拦截器和过滤器的异同 相同点 都是aop编程思想的体现，可以在程序执行前后做一些操作，如权限操作，日志记录等 不同点： Filter是Servlet规范中定义的，拦截器是Spring框架中的 触发时机不一样，过滤器是在请求进入容器后，但请求进入servlet之前进行预处理的 拦截器可以获取IOC容器中的各个bean，而过滤器就不行，拦截器归Spring管理 Springboot实现过滤器和拦截器第一步：定义Filter12345678910@Slf4jpublic class TestFilter implements Filter { @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { log.info(\"TestFilter filter。。。。。。。。\"); filterChain.doFilter(servletRequest, servletResponse); }} 第二步：注入springboot容器当中1234567891011121314151617@Configurationpublic class FilterConfig { @Bean Filter testFilter(){ return new TestFilter(); } @Bean public FilterRegistrationBean&lt;TestFilter&gt; filterRegistrationBean1(){ FilterRegistrationBean&lt;TestFilter&gt; filterRegistrationBean=new FilterRegistrationBean&lt;&gt;(); filterRegistrationBean.setFilter((TestFilter) testFilter()); filterRegistrationBean.addUrlPatterns(\"/*\"); //filterRegistrationBean.setOrder();多个filter的时候order的数值越小 则优先级越高 return filterRegistrationBean; }} 第三步：定义拦截器123456789101112131415161718192021@Slf4j@Service(value = \"testInterceptor\")public class TestInterceptor implements HandlerInterceptor { @Override public boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { log.info(\"TestInterceptor preHandle....\"); return true; } @Override public void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable ModelAndView modelAndView) throws Exception { log.info(\"TestInterceptor postHandle....\"); } @Override public void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, @Nullable Exception ex) throws Exception { log.info(\"TestInterceptor afterCompletion....\"); }} 第四步：加入springboot容器123456789101112@Configurationpublic class InterceptorConfig implements WebMvcConfigurer { @Autowired TestInterceptor testInterceptor; @Override public void addInterceptors(InterceptorRegistry registry) { registry.addInterceptor(testInterceptor) .addPathPatterns(\"/api/**\"); }} 注意：这边用的springboot是2.0.x，采取的是直接实现WebMvcConfigurer，因为WebMvcConfigurerAdapter被标识了@Deprecated，就没有继承WebMvcConfigurerAdapter了123456/** @deprecated */@Deprecatedpublic abstract class WebMvcConfigurerAdapter implements WebMvcConfigurer { public WebMvcConfigurerAdapter() { }} 第五步：还是启动之前的controller12345678910@RestController@RequestMapping(\"/api/test\")@Slf4jpublic class TestController { @RequestMapping(value = \"/hello\") public String test() { log.info(\"test hello.............\"); return \"SUCCESS\"; } 看到打印结果如下12342019-04-27/12:01:04.603||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.filter.TestFilter 22 - TestFilter filter。。。。。。。。2019-04-27/12:01:04.612||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.interceptor.TestInterceptor 26 - TestInterceptor preHandle....2019-04-27/12:01:04.634||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.interceptor.TestInterceptor 32 - TestInterceptor postHandle....2019-04-27/12:01:04.634||||||||^_^|[http-nio-8088-exec-1] INFO com.stone.zplxjj.interceptor.TestInterceptor 37 - TestInterceptor afterCompletion.... 小结过滤器的实现基于回调函数。而拦截器（代理模式）的实现基于反射，代理又分静态代理和动态代理，动态代理是拦截器的简单实现。那何时使用拦截器？何时使用过滤器？ 如果是非spring项目，那么拦截器不能用，只能使用过滤器，这里说的拦截器是基于spring的拦截器。 如果是处理controller前后，既可以使用拦截器也可以使用过滤器，如果都使用了，注意前后顺序。 如果是处理dispaterServlet前后，只能使用过滤器。","link":"/2019/04/27/springboot/"},{"title":"springcloud(一)——spring-cloud-alibaba集成rocketmq","text":"前言在之前的工作中，微服务框架使用的是springcloud，消息中间件使用的rocketmq，这段时间看到阿里出了spring cloud alibaba集成了rocketmq，出于好奇，写了个demo 一些概念 官方对 Spring Cloud Stream 的一段介绍：Spring Cloud Stream 是一个用于构建基于消息的微服务应用框架。基于 SpringBoot 创建具有生产级别的单机 Spring 应用，并且使用 Spring Integration 与 Broker 进行连接。 Binder ：Components responsible to provide integration with the external messaging systems.【与外部消息中间件进行集成】 Binding：Bridge between the external messaging systems and application provided Producers and Consumers of messages (created by the Destination Binders).【在消息中间件与应用程序提供的 Provider 和 Consumer 之间提供了一个桥梁，开发者只需使用应用程序的 生产者或消费者生产或消费数据即可，屏蔽了开发者与底层消息中间件的接触。】 Message: The canonical data structure used by producers and consumers to communicate with Destination Binders (and thus other applications via external messaging systems).【生产者和消费者用于与目标绑定器通信的规范数据结构。】 快速在本地启动rocketmq第一步：下载：https://www.apache.org/dyn/closer.cgi?path=rocketmq/4.3.2/rocketmq-all-4.3.2-bin-release.zip第二步：解压第三步：修改三个配置文件：runbroker.sh,runserver.sh,tools.sh,将其中JAVA_HOME改成自己电脑的环境配置,修改完如下123[ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; JAVA_HOME=自己的地址#[ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; JAVA_HOME=/usr/java[ ! -e \"$JAVA_HOME/bin/java\" ] &amp;&amp; error_exit \"Please set the JAVA_HOME variable in your environment, We need java(x64)!\" 第四步：依次执行命令123./mqnamesrv./mqbroker -n localhost:9876./mqadmin updateTopic -n localhost:9876 -c DefaultCluster -t test-topic 如果启动成功，没有报错，代表启动成功哈，下面就可以开发了 开发demo第一步：导入相关的pom1234567&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt; 1234567891011121314151617181920212223&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-stream-rocketmq&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; &lt;!-- 为了Endpoint 信息查看 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-actuator&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.dropwizard.metrics&lt;/groupId&gt; &lt;artifactId&gt;metrics-core&lt;/artifactId&gt; &lt;version&gt;3.2.6&lt;/version&gt;&lt;/dependency&gt; 第二步：建一个springboot项目，启动类如下：1234567@SpringBootApplication@EnableBinding({ Source.class, Sink.class })public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 第三步：创建provider1234567891011@Servicepublic class RocketmqProducer { public void send(String message) throws MQClientException, RemotingException, InterruptedException, MQBrokerException { DefaultMQProducer producer = new DefaultMQProducer(\"test_producer_group\"); producer.setNamesrvAddr(\"127.0.0.1:9876\"); producer.start(); Message msg = new Message(\"test-topic\", \"test-tag\", message.getBytes()); producer.send(msg); }} 第四步：创建consumer12345678910111213@Servicepublic class ReceiveService { /** * 默认是input，在Sink类中指定，如果想要多个input，需要写一个实现Sink的类 * @param receiveMsg */ @StreamListener(\"input\") public void receiveInput1(String receiveMsg) { System.out.println(\"input receive: \" + receiveMsg); }} 第五步：加入配置文件：1234567891011121314server.port=8087spring.application.name=spring-cloud-alibaba-rocketmq-demo# 配置rocketmq的nameserver地址spring.cloud.stream.rocketmq.binder.namesrv-addr=127.0.0.1:9876# 定义name为output的bindingspring.cloud.stream.bindings.output.destination=test-topicspring.cloud.stream.bindings.output.content-type=application/json#定义name为input的bindingspring.cloud.stream.bindings.input.destination=test-topicspring.cloud.stream.bindings.input.content-type=application/jsonspring.cloud.stream.bindings.input.group=test-groupmanagement.endpoint.health.show-details=always 第六步：写一个controller，启动项目，访问接口12345678910111213@RestController@RequestMapping(value = \"/api/demo/test\")public class TestController { @Autowired RocketmqProducer rocketmqProducer; @RequestMapping(value = \"/send\", method = RequestMethod.GET) public String send() throws InterruptedException, RemotingException, MQClientException, MQBrokerException { rocketmqProducer.send(\"test rocketmq message\"); return \"success\"; }} 会看到控制台输出：input receive: test rocketmq message Endpoint 信息查看浏览器输入：http://127.0.0.1:8087/actuator/rocketmq-binder 结语这一篇文章只是将spring cloud stream 和 rocketmq跑通了，其实对于spring cloud stream和rocketmq还是学习的阶段，只能感叹spring cloud博大精深","link":"/2019/04/29/spring-cloud/"},{"title":"springcloud(二)——spring-cloud-alibaba集成sentinel入门","text":"Sentinel 介绍随着微服务的流行，服务和服务之间的稳定性变得越来越重要。 Sentinel 以流量为切入点，从流量控制、熔断降级、系统负载保护等多个维度保护服务的稳定性。 Sentinel 具有以下特征: 丰富的应用场景： Sentinel 承接了阿里巴巴近 10 年的双十一大促流量的核心场景，例如秒杀（即突发流量控制在系统容量可以承受的范围）、消息削峰填谷、实时熔断下游不可用应用等。 完备的实时监控： Sentinel 同时提供实时的监控功能。您可以在控制台中看到接入应用的单台机器秒级数据，甚至 500 台以下规模的集群的汇总运行情况。 广泛的开源生态： Sentinel 提供开箱即用的与其它开源框架/库的整合模块，例如与 Spring Cloud、Dubbo、gRPC 的整合。您只需要引入相应的依赖并进行简单的配置即可快速地接入 Sentinel。 完善的 SPI 扩展点： Sentinel 提供简单易用、完善的 SPI 扩展点。您可以通过实现扩展点，快速的定制逻辑。例如定制规则管理、适配数据源等。 springcloud如何使用 Sentinel第一步：引入pom123456789101112131415161718192021 &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-alibaba-dependencies&lt;/artifactId&gt; &lt;version&gt;0.2.1.RELEASE&lt;/version&gt; &lt;type&gt;pom&lt;/type&gt; &lt;scope&gt;import&lt;/scope&gt; &lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-sentinel&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; 第二步：新建一个启动类和controller123456789101112131415@SpringBootApplicationpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }}@RestControllerpublic class TestController { @GetMapping(value = \"/hello\") @SentinelResource(\"hello\") public String hello() { return \"Hello Sentinel\"; }} 第三步：引入dashboard可以直接下载sentinel-dashboard的jar包，也可以自己编译，我这边这里clone了代码自己编译，代码地址：https://github.com/alibaba/Sentinel,执行命令1mvn clean package 会得到：sentinel-dashboard.jar，执行命令启动dashboard：1java -jar sentinel-dashboard.jar 这样默认是8080端口，在浏览器输入：http://localhost:8080，默认账号密码：sentinel:sentinel，看到控制台界面为部署成功： 第四步：引入配置：12345server.port=8088spring.application.name=spring-cloud-alibaba-sentinel-demo# sentinel dashboardspring.cloud.sentinel.transport.dashboard=localhost:8080 第五步：启动spring boot 项目，继续访问localhost:8080,会看到如下界面 第六步：使用Sentinel实现接口限流(在控制台) 第七步：测试通过上面的配置，实现的是/hello接口qps最大是2，如果qps大于2，则快速失败，配置完成，点击保存，我们快速刷新浏览器，会发现快速失败 结语这篇文章只是springcloud和sentinel的入门，复杂的一些代码配置和文件配置后期介绍","link":"/2019/05/11/springcloud/"},{"title":"java混淆了吗","text":"前言最近在项目中碰到个一个场景，我们需要把自己的java项目jar包部署到一个第三方的服务器上，虽然双方互相信任，但是综合考虑，避免别人拿到jar包后可以很快的编译出源码，我们决定给代码加一层混淆，虽然此方法不能从根源上解决问题，但是做了一层混淆，也可以增加阅读源码的难度，总结了一下，写下这篇文章。 如何反编译java代码我用的是mac电脑，从官网:http://java-decompiler.github.io/#jd-gui-download下载JD-GUI，官网有很多版本，下载后安装打开即可，导入你想反编译的jar，我这里随便找了个jar包做演示 何为java混淆细心的小伙伴肯定发现了，上面的截图有的包名是a，b，c这样命名的，但凡有点节操的程序员都不会这样命名的，这就是被混淆后的代码，让人不会一眼看出来代码里面的逻辑，效果会像下面这样可以看到类名，包名都被修改了 进行java混淆我们以之前springboot项目为例，进行service层的代码的混淆，呼啸前效果如下： 接下来我们只需要在pom里面加入如下插件123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102 &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.7&lt;/source&gt; &lt;target&gt;1.7&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;com.github.wvengen&lt;/groupId&gt; &lt;artifactId&gt;proguard-maven-plugin&lt;/artifactId&gt; &lt;version&gt;2.0.14&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;phase&gt;package&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;proguard&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;proguardVersion&gt;6.1.0beta2&lt;/proguardVersion&gt; &lt;injar&gt;${project.build.finalName}.jar&lt;/injar&gt; &lt;outjar&gt;${project.build.finalName}.jar&lt;/outjar&gt; &lt;obfuscate&gt;true&lt;/obfuscate&gt; &lt;options&gt; &lt;option&gt;-dontshrink&lt;/option&gt; &lt;option&gt;-dontoptimize&lt;/option&gt; &lt;!-- This option will replace all strings in reflections method invocations with new class names. For example, invokes Class.forName('className')--&gt; &lt;option&gt;-adaptclassstrings&lt;/option&gt; &lt;option&gt;-keepdirectories&lt;/option&gt; &lt;!-- This option will save all original annotations and etc. Otherwise all we be removed from files.--&gt; &lt;option&gt;-keepattributes Exceptions, InnerClasses, Signature, Deprecated, SourceFile, LineNumberTable, *Annotation*, EnclosingMethod &lt;/option&gt; &lt;!-- This option will save all original names in interfaces (without obfuscate).--&gt; &lt;option&gt;-keepnames interface **&lt;/option&gt; &lt;!-- This option will save all original methods parameters in files defined in -keep sections, otherwise all parameter names will be obfuscate.--&gt; &lt;option&gt;-keepparameternames&lt;/option&gt; &lt;!--不使用大小写字母进行混淆，保持类唯一性--&gt; &lt;option&gt;-dontusemixedcaseclassnames&lt;/option&gt; &lt;!-- This option will save all original class files (without obfuscate) but obfuscate all in domain and service packages.--&gt; &lt;option&gt;-keep class com.stone.zplxjj.Application { public static void main(java.lang.String[]); } &lt;/option&gt; &lt;!-- 指明哪些类可以不被混淆--&gt; &lt;option&gt;-keep class com.stone.zplxjj.autoconfiguration.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.config.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.controller.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.dao.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.entity.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.event.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.interceptor.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.listener.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.properties.** { *; }&lt;/option&gt; &lt;option&gt;-keep class com.stone.zplxjj.filter.** { *; }&lt;/option&gt; &lt;!-- This option ignore warnings such as duplicate class definitions and classes in incorrectly named files--&gt; &lt;option&gt;-ignorewarnings&lt;/option&gt; &lt;!-- This option will save all original class files (without obfuscate) in service package--&gt; &lt;!--&lt;option&gt;-keep class com.slm.proguard.example.spring.boot.service { *; }&lt;/option&gt;--&gt; &lt;!-- This option will save all original interfaces files (without obfuscate) in all packages.--&gt; &lt;option&gt;-keep interface * extends * { *; }&lt;/option&gt; &lt;!-- This option will save all original defined annotations in all class in all packages.--&gt; &lt;option&gt;-keepclassmembers class * { @org.springframework.beans.factory.annotation.Autowired *; @org.springframework.beans.factory.annotation.Value *; } &lt;/option&gt; &lt;/options&gt; &lt;injarNotExistsSkip&gt;true&lt;/injarNotExistsSkip&gt; &lt;libs&gt; &lt;!--Put here your libraries if required--&gt; &lt;lib&gt;${java.home}/lib/rt.jar&lt;/lib&gt; &lt;/libs&gt; &lt;/configuration&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;net.sf.proguard&lt;/groupId&gt; &lt;artifactId&gt;proguard-base&lt;/artifactId&gt; &lt;version&gt;6.1.0beta2&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt;&lt;/plugin&gt;&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt;&lt;/plugin&gt; 执行打包命令：mvn package，会看到生成如下我们看到了生成了不只一个jar包，还有一些别的文件，这个我们放后面介绍，我们先看下划红线的jar反编译后的效果可以看到我们针对service包下面的类混淆成功了 注意点 zplxjj_proguard_base.jar是没有经过混淆的jar 两个.txt文件说明了混淆前和混淆后的对应关系 如果项目中引入了spring框架，类的注入id要保持唯一性，否则就要重写生成bean的id规则的方法 更多pom文件细节可以参考：https://www.guardsquare.com/en/products/proguard/manual/usage#obfuscationoptions","link":"/2019/06/10/java/"},{"title":"git的一些撤销操作","text":"前言在用开发项目的时候，经常会写着写着会发现写错的时候，人生没有后悔药，但是git有啊，大不了从头再来嘛。 git的一些撤销操作代码还没有存到暂存区当我们修改了一个文件，还没有执行git add操作的时候，发现写错的时候.123➜ xiaoyan_es_static git:(master) ✗ cat README.mdes日志统计查询我写错了,不想要这行了 我们可以使用如下命令，回到最后一次提交的版本1git checkout -- &lt;file&gt;... 执行完git checkout – README.md 命令后12➜ xiaoyan_es_static git:(master) ✗ cat README.mdes日志统计查询 代码存储到了暂存区当我们一不小心将代码存入了暂存区123456789➜ xiaoyan_es_static git:(master) ✗ git add .➜ xiaoyan_es_static git:(master) ✗ git statusOn branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: README.md 我们可以使用如下命令，回到最后一次提交的版本1git reset HEAD &lt;file&gt;... 执行完命令后如下所示12345678910111213➜ xiaoyan_es_static git:(master) ✗ cat README.md es日志统计查询这行写错了，但是已经存到暂存区了% ➜ xiaoyan_es_static git:(master) ✗ git status On branch masterYour branch is up-to-date with &apos;origin/master&apos;.Changes not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: README.mdno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 代码已经commit了当我们修改的代码已经commit了，我们只需要执行1➜ xiaoyan_es_static git:(master) git reset --hard HEAD^ 上一个版本就是HEAD^，上上一个版本就是HEAD^^，当然往上100个版本写100个^比较容易数不过来，所以写成HEAD~100。 ###代码已经push到远程了少年，你怎么这么冲动呢 git的一些其它操作当我们需要删除暂存区或分支上的文件, 同时工作区也不需要这个文件了, 可以使用123git rm file_pathgit commit -m &apos;delete somefile&apos;git push 当我们需要删除暂存区或分支上的文件, 但本地又需要使用, 只是不希望这个文件被版本控制, 可以使用123git rm --cached file_pathgit commit -m &apos;delete remote somefile&apos;git push 当我们对文件或者文件夹执行过chmod操作时，执行git diff会出现类似’ old mode xxx new mode xxx’,这个时候我们只需要执行如下命令即可1git config --add core.filemode false 这样你的所有的git库都会忽略filemode变更了～","link":"/2019/06/27/git/"},{"title":"elasticsearch+logstash+kibana 7.2.0版本搭建","text":"前言最近看了elasticsearch出了7.x的版本，加上项目中用elasticsearch挺频繁，索性记录下学习的过程，一开始，准备在本机上面搭建ELK 搭建ELK——elasticsearch第一步选择合适的版下载本：https://www.elastic.co/cn/downloads/elasticsearch 第二步下载完成后解压后进入目录12➜ elasticsearch-7.2.0 lsLICENSE.txt NOTICE.txt README.textile bin config data jdk lib logs modules plugins 第三步启动命令：1bin/elasticsearch 第四步浏览器输入地址：http://localhost:9200看到如下界面为安装成功1234567891011121314151617{ \"name\": \"zhangpeileideMacBook-Pro.local\", \"cluster_name\": \"elasticsearch\", \"cluster_uuid\": \"s_wuhCF5Q_-pf7iZ5NNxYg\", \"version\": { \"number\": \"7.2.0\", \"build_flavor\": \"default\", \"build_type\": \"tar\", \"build_hash\": \"508c38a\", \"build_date\": \"2019-06-20T15:54:18.811730Z\", \"build_snapshot\": false, \"lucene_version\": \"8.0.0\", \"minimum_wire_compatibility_version\": \"6.8.0\", \"minimum_index_compatibility_version\": \"6.0.0-beta1\" }, \"tagline\": \"You Know, for Search\"} 搭建ELK——logstash第一步：选择合适的版本下载：https://www.elastic.co/cn/downloads/logstash 第二步：进入解压后目录：123➜ logstash-7.2.0 lsCONTRIBUTORS Gemfile.lock NOTICE.TXT config lib logstash-core modules vendorGemfile LICENSE.txt bin data logs logstash-core-plugin-api tools x-pack 第三步进入config目录后，修改logstash.conf文件如下12345678910111213141516# Sample Logstash configuration for creating a simple# Beats -&gt; Logstash -&gt; Elasticsearch pipeline.input { file{ path =&gt; &quot;/Users/zhangpeilei/test.txt&quot; }}output { elasticsearch { hosts =&gt; [&quot;http://localhost:9200&quot;] index =&gt; &quot;test-%{+YYYY.MM.dd}&quot; #user =&gt; &quot;elastic&quot; #password =&gt; &quot;changeme&quot; }} 实现效果：将/Users/zhangpeilei/test.txt文件内容写入到ES 第四步执行启动命令1bin/logstash -f config/logstash.conf 搭建ELK——Kibana第一步选择合适的版下载本：https://www.elastic.co/cn/downloads/kibana 第二步进入解压后目录12➜ kibana-7.2.0-darwin-x86_64 lsLICENSE.txt NOTICE.txt README.txt bin built_assets config data node node_modules optimize package.json plugins src target webpackShims x-pack 第三步配置文件config/kibana.yml修改这一行：elasticsearch.hosts: [“http://localhost:9200&quot;] 第四步启动:1bin/kibana 启动ELK浏览器输入：http://localhost:5601配置完索引后即可看到数据","link":"/2019/07/25/elasticsearch/"},{"title":"git版本库迁移","text":"背景今天工作中碰到个需求，需要将git里面groupA中的一个项目迁移到groupB中，通常麻烦点的做法就是在groupB中建一个新项目，将所有代码拷贝过去，但是这样的话，所有的分支和历史记录就没有了。 基于此，有没有一个好办法呢，可以通过命令行的操作，就将一个项目完整的迁移过去呢。在网上查询了一些资料，找到了这样的方法，在这里做一个记录 迁移步骤第一步：克隆老项目到本地的一个目录下1git clone --bare git@git.xxx.com:groupA/old_project.git 第二步：进入目录12➜ ~ cd old_project.git➜ old_project.git git:(master) 第三步：在groupB新建一个项目：new_project1git push --mirror git@git.xxx.com:groupB/new_project.git 基于此，项目完整的从groupA迁移到groupB了第四步：删除老版本，重新克隆新版本就可以了 备注–bare 创建的克隆版本库都不包含工作区，直接就是版本库的内容，这样的版本库称为裸版本库。 更多内容欢迎访问博客：http://www.zplxjj和个人公众号","link":"/2019/09/24/git/"},{"title":"xxl-job学习笔记(一)——使用xxl-job搭建作业调度平台","text":"前言最近项目需要引入作业调度相关功能，打算引入xxl-job，因为之前在公司参与过作业调度相关的开发，打算系统的记录下学习使用和分析的过程 搭建调度中心抛开架构和原理，拿到一个新东西，首先让我们能够使用起来，搭建一个自己的任务第一步: 下载源码下载地址：https://github.com/xuxueli/xxl-job/第二步: 执行sql文件地址：xxl-job/doc/db/tables_xxl_job.sql第三步: 修改xxl-job-admin项目配置配置文件：application.properties配置项：1234### xxl-job, datasourcespring.datasource.url=${datasource.url}spring.datasource.username=${datasource.username}spring.datasource.password=${datasource.password} 打包命令:1xxl-job-admin git:(master) ✗ mvn clean -U package -Dmaven.test.skip=true 启动命令：12➜ xxl-job-admin git:(master) ✗ cd target ➜ target git:(master) ✗ java -jar xxl-job-admin-2.1.0.jar 访问http://localhost:18827/xxl-job-admin账号：admin密码：123456看到如下页面即搭建成功 编写代码第一步： 搭建一个springboot项目，application.properties加入如下配置：12345678910111213141516# web portserver.port=8081# log configlogging.config=classpath:logback.xml### xxl-job admin address list, such as &quot;http://address&quot; or &quot;http://address01,http://address02&quot;xxl.job.admin.addresses=http://127.0.0.1:8080/xxl-job-admin### xxl-job executor addressxxl.job.executor.appname=xxl-job-executor-samplexxl.job.executor.ip=xxl.job.executor.port=9999### xxl-job, access tokenxxl.job.accessToken=### xxl-job log pathxxl.job.executor.logpath=/data/applogs/xxl-job/jobhandler### xxl-job log retention daysxxl.job.executor.logretentiondays=-1 第二步： 编写配置类12345678910111213141516171819202122232425262728293031323334353637383940@Configurationpublic class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(\"${xxl.job.admin.addresses}\") private String adminAddresses; @Value(\"${xxl.job.executor.appname}\") private String appName; @Value(\"${xxl.job.executor.ip}\") private String ip; @Value(\"${xxl.job.executor.port}\") private int port; @Value(\"${xxl.job.accessToken}\") private String accessToken; @Value(\"${xxl.job.executor.logpath}\") private String logPath; @Value(\"${xxl.job.executor.logretentiondays}\") private int logRetentionDays; @Bean(initMethod = \"start\", destroyMethod = \"destroy\") public XxlJobSpringExecutor xxlJobExecutor() { logger.info(\"&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.\"); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppName(appName); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } 第三步： 编写jobhandler12345678910111213141516@JobHandler(value=\"demoJobHandler\")@Componentpublic class DemoJobHandler extends IJobHandler { @Override public ReturnT&lt;String&gt; execute(String param) throws Exception { XxlJobLogger.log(\"XXL-JOB, Hello World.\"); for (int i = 0; i &lt; 5; i++) { XxlJobLogger.log(\"beat at:\" + i); TimeUnit.SECONDS.sleep(2); } return SUCCESS; }} 第四步： 启动springboot项目后，配置执行器 点击保存后出现这个，即为配置成功第五步: 配置jobhandler，新增任务第六步: 点击执行一次看看效果 到此springboot整合xxl-job就完成了，在后续添加任务时，只需要编写相应的handler去继承IJobHandler即可","link":"/2019/09/03/xxl-job/"},{"title":"springboot(三)——application.properties和application.yml是何时解析的","text":"前言用过的springboot的小伙伴都知道springboot不需要再像springmvc引入那么多的配置文件，只需要加入application.properties或者application.yml即可，比如在上一篇文章讲到数据库的配置，只需要在文件引入如下的配置即可：1234spring.datasource.url=jdbc:mysql://127.0.0.1:3306/zplxjj?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=GMT%2B8spring.datasource.username=rootspring.datasource.password=@ZPLxjj12345spring.datasource.driver-class-name=com.mysql.jdbc.Driver 下面简单介绍下springboot在启动的时候是在何时读取的properties和yml文件的内容的 实现一个简单的自定义监听器第一步：定义一个event，继承ApplicationEvent123456public class CustomerApplicationEvent extends ApplicationEvent { public CustomerApplicationEvent(Object source) { super(source); System.out.println(\"CustomerApplicationEvent constructor...\"); }} 第二步：定义一个listener12345678@Componentpublic class CustomerApplicationListener implements ApplicationListener&lt;CustomerApplicationEvent&gt; { @Override public void onApplicationEvent(CustomerApplicationEvent customerApplicationEvent) { System.out.println(\"customerApplicationEvent:\"+customerApplicationEvent.getClass().getName()); }} 第三步：注册监听器12345678910@SpringBootApplicationpublic class Application { public static void main(String[] args) { ConfigurableApplicationContext context = SpringApplication.run(Application.class, args); // 注册 CustomerApplicationListener 事件监听器 context.addApplicationListener(new CustomerApplicationListener()); // 发布 CustomerApplicationEvent 事件 context.publishEvent(new CustomerApplicationEvent(new Object())); }} 启动项目后，会发现控制台输出了：12CustomerApplicationEvent constructor...customerApplicationEvent:com.stone.zplxjj.event.CustomerApplicationEvent springboot自带的事件 ApplicationStartingEvent：应用启动事件，在调用 SpringApplication.run() 方法之前，可以从中获取到 SpringApplication 对象，进行一些启动前设置。 ApplicationEnvironmentPreparedEvent：Environment准备完成事件，此时可以从中获取到 Environment 对象并对其中的配置项进行查看或者修改。 ApplicationPreparedEvent：ApplicationContext准备完成事件，接下来 Spring 就能够向容器中加载 Bean 了 。 ApplicationReadyEvent：应用准备完成事件，预示着应用可以接收和处理请求了。 ApplicationFailedEvent：应用启动失败事件，可以从中捕获到启动失败的异常信息进行相应处理，例如：添加虚拟机对应的钩子进行资源的回收与释放。 读取配置代码入口：ApplicationEnvironmentPreparedEvent和ConfigFileApplicationListener加载配置文件需要用到ConfigFileApplicationListener，其代码如下：12345678910@Overridepublic void onApplicationEvent(ApplicationEvent event) { if (event instanceof ApplicationEnvironmentPreparedEvent) { onApplicationEnvironmentPreparedEvent( (ApplicationEnvironmentPreparedEvent) event); } if (event instanceof ApplicationPreparedEvent) { onApplicationPreparedEvent(event); }} 进入方法：onApplicationEnvironmentPreparedEvent12345678910private void onApplicationEnvironmentPreparedEvent( ApplicationEnvironmentPreparedEvent event) { List&lt;EnvironmentPostProcessor&gt; postProcessors = loadPostProcessors(); postProcessors.add(this); AnnotationAwareOrderComparator.sort(postProcessors); for (EnvironmentPostProcessor postProcessor : postProcessors) { postProcessor.postProcessEnvironment(event.getEnvironment(), event.getSpringApplication()); }} 进入postProcessor.postProcessEnvironment：123456 //类：ConfigFileApplicationListener@Overridepublic void postProcessEnvironment(ConfigurableEnvironment environment, SpringApplication application) { addPropertySources(environment, application.getResourceLoader());} 进入addPropertySources1234567protected void addPropertySources(ConfigurableEnvironment environment, ResourceLoader resourceLoader) { //将随机方法放入到PropertySources中 RandomValuePropertySource.addToEnvironment(environment); //load加载 new Loader(environment, resourceLoader).load();} 进入load方法：1234567891011121314151617181920public void load() { this.profiles = new LinkedList&lt;&gt;(); this.processedProfiles = new LinkedList&lt;&gt;(); this.activatedProfiles = false; this.loaded = new LinkedHashMap&lt;&gt;(); initializeProfiles(); while (!this.profiles.isEmpty()) { Profile profile = this.profiles.poll(); if (profile != null &amp;&amp; !profile.isDefaultProfile()) { addProfileToEnvironment(profile.getName()); } load(profile, this::getPositiveProfileFilter, addToLoaded(MutablePropertySources::addLast, false)); this.processedProfiles.add(profile); } resetEnvironmentProfiles(this.processedProfiles); load(null, this::getNegativeProfileFilter, addToLoaded(MutablePropertySources::addFirst, true)); addLoadedPropertySources();} 进入字方法load123456789 private void load(Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) { getSearchLocations().forEach((location) -&gt; { boolean isFolder = location.endsWith(\"/\"); Set&lt;String&gt; names = isFolder ? getSearchNames() : NO_SEARCH_NAMES; names.forEach( (name) -&gt; load(location, name, profile, filterFactory, consumer)); });} getSearchLocations():首先看CONFIG_LOCATION_PROPERTY，是否存在配置，无则走默认配置路径DEFAULT_SEARCH_LOCATIONS 1234567/** * The \"config location\" property name. */public static final String CONFIG_LOCATION_PROPERTY = \"spring.config.location\";// Note the order is from least to most specific (last one wins)private static final String DEFAULT_SEARCH_LOCATIONS = \"classpath:/,classpath:/config/,file:./,file:./config/\"; getSearchNames():首先看CONFIG_NAME_PROPERTY(spring.config.name)配置，否则走DEFAULT_NAMES(application) spring.config.name说明：假如你不喜欢“application.properties”这个默认文件名，你可以重新设定：spring.config.name属性直接指定属性文件名称，spring.config.location属性指定明确路径，但是要注意不能写在application.properties文件里，这样会不起作用，可以写在java -jar xxx.jar –spring.config.name=custom.properties,还可以通过环境变量等方式,yml文件也可以这样 真正加载配置文件的方法：123456789101112131415161718192021private void load(String location, String name, Profile profile, DocumentFilterFactory filterFactory, DocumentConsumer consumer) { if (!StringUtils.hasText(name)) { for (PropertySourceLoader loader : this.propertySourceLoaders) { if (canLoadFileExtension(loader, location)) { load(loader, location, profile, filterFactory.getDocumentFilter(profile), consumer); return; } } } Set&lt;String&gt; processed = new HashSet&lt;&gt;(); for (PropertySourceLoader loader : this.propertySourceLoaders) { for (String fileExtension : loader.getFileExtensions()) { if (processed.add(fileExtension)) { loadForFileExtension(loader, location + name, \".\" + fileExtension, profile, filterFactory, consumer); } } }} loader.getFileExtensions():获取所有支持的文件后缀,loader初始化如下：1234Loader(ConfigurableEnvironment environment, ResourceLoader resourceLoader) { this.propertySourceLoaders = SpringFactoriesLoader.loadFactories( PropertySourceLoader.class, getClass().getClassLoader());} 通过加载jar:spring-boot-2.1.4.RELEASE.jar:META-INF/spring.factories文件下对应内容：1234# PropertySource Loadersorg.springframework.boot.env.PropertySourceLoader=\\org.springframework.boot.env.PropertiesPropertySourceLoader,\\org.springframework.boot.env.YamlPropertySourceLoader 从这里我们可以看到，通过PropertiesPropertySourceLoader和YamlPropertySourceLoader加载配置文件，具体源码没有细看了，有兴趣自行阅读吧 加载完配置文件，调用方法：addLoadedPropertySources() 结语至此，springboot加载properties和yml的入口就分析到这里了，细节上肯定不能面面俱到，但是入口知道了，后面就好分析了","link":"/2019/04/24/springboot-1/"},{"title":"springboot(二)——springboot自动配置解析","text":"前言用过springboot的同学肯定很熟悉，它其中有个重要的特性，就是自动配置(平时习惯的一些设置的配置作为默认配置)。springboot提倡无XML配置文件的理念，使用springboot生成的应用完全不会生成任何配置代码与XML配置文件。下面先看一个springboot集成mybatis的例子。第一步： 引入pom文件12345678910&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.0.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;5.1.47&lt;/version&gt;&lt;/dependency&gt; 第二步： 因为我使用的xml配置文件去使用mybatis，在application.properties文件加入如下配置：12345678#指定mapper文件位置mybatis.mapper-locations=classpath:mapper/*.xml#数据源信息spring.datasource.url=jdbc:mysql://127.0.0.1:3306/zplxjj?useUnicode=true&amp;characterEncoding=utf8&amp;useSSL=false&amp;serverTimezone=GMT%2B8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver 第三步： 加入实体类、dao、mapper文件第四步：启动类上面加入注解1234567@SpringBootApplication@MapperScan(\"com.stone.zplxjj.dao\")public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 第五步：至此，配置完成，只需要写个单侧，springboot已经完美集成mybatis1234567891011@RunWith(SpringRunner.class)@SpringBootTestpublic class ApplicationTests { @Autowired UserMapper userMapper; @Test public void testMybatis() { System.out.println(userMapper.selectByPrimaryKey(1L)); }} @EnableAutoConfiguration通过上面的例子，我们发现集成mybatis特别简单，那些繁琐的类的注入都没有写，只需要加入数据库的一些配置即可，那这其中@EnableAutoConfiguration功不可没。@EnableAutoConfiguration 注解已经在@SpringBootApplication里面了1234567891011121314151617181920212223242526272829303132333435363738@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = {@Filter( type = FilterType.CUSTOM, classes = {TypeExcludeFilter.class}), @Filter( type = FilterType.CUSTOM, classes = {AutoConfigurationExcludeFilter.class})})public @interface SpringBootApplication { @AliasFor( annotation = EnableAutoConfiguration.class ) Class&lt;?&gt;[] exclude() default {}; @AliasFor( annotation = EnableAutoConfiguration.class ) String[] excludeName() default {}; @AliasFor( annotation = ComponentScan.class, attribute = \"basePackages\" ) String[] scanBasePackages() default {}; @AliasFor( annotation = ComponentScan.class, attribute = \"basePackageClasses\" ) Class&lt;?&gt;[] scanBasePackageClasses() default {};} 我们看到@EnableAutoConfiguration结构如下：12345678910111213@Target({ElementType.TYPE})@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import({AutoConfigurationImportSelector.class})public @interface EnableAutoConfiguration { String ENABLED_OVERRIDE_PROPERTY = \"spring.boot.enableautoconfiguration\"; Class&lt;?&gt;[] exclude() default {}; String[] excludeName() default {};} 这其中起作用的一个重要注解@Import，这个Spring提供的一个注解，可以导入配置类或者Bean到当前类中，我们进入到AutoConfigurationImportSelector类中查看，方法太长，截取核心的两个方法：12345678910111213141516171819202122232425public String[] selectImports(AnnotationMetadata annotationMetadata) { if (!this.isEnabled(annotationMetadata)) { return NO_IMPORTS; } else { AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader.loadMetadata(this.beanClassLoader); AutoConfigurationImportSelector.AutoConfigurationEntry autoConfigurationEntry = this.getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations()); }}protected AutoConfigurationImportSelector.AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) { if (!this.isEnabled(annotationMetadata)) { return EMPTY_ENTRY; } else { AnnotationAttributes attributes = this.getAttributes(annotationMetadata); List&lt;String&gt; configurations = this.getCandidateConfigurations(annotationMetadata, attributes); configurations = this.removeDuplicates(configurations); Set&lt;String&gt; exclusions = this.getExclusions(annotationMetadata, attributes); this.checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = this.filter(configurations, autoConfigurationMetadata); this.fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationImportSelector.AutoConfigurationEntry(configurations, exclusions); }} 通过项目启动后，打上注解，可以看到MybatisAutoConfiguration引入了进来而MybatisAutoConfiguration能引入进来，其实是在mybatis-spring-boot-autoconfigure-2.0.1.jar包里面的spring.factories指定的,通过调用SpringFactoriesLoader.loadFactoryNames()来扫描加载含有META-INF/spring.factories文件的jar包，从而标识哪些自动配置的类123# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\\org.mybatis.spring.boot.autoconfigure.MybatisAutoConfiguration @Conditional@Conditional 的作用，可以根据条件去加载特定的bean，原理这边不做探讨，springboot基于此实现了几个注解，比较方便的实现条件加载类@ConditionalOnBean：Spring容器中是否存在对应的实例@ConditionalOnMissingBean：Spring容器中是否缺少对应的实例通过查看MybatisAutoConfiguration中的SqlSessionFactory的写法1234567891011121314151617181920212223242526272829303132333435363738394041@Bean@ConditionalOnMissingBeanpublic SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception { SqlSessionFactoryBean factory = new SqlSessionFactoryBean(); factory.setDataSource(dataSource); factory.setVfs(SpringBootVFS.class); if (StringUtils.hasText(this.properties.getConfigLocation())) { factory.setConfigLocation(this.resourceLoader.getResource(this.properties.getConfigLocation())); } this.applyConfiguration(factory); if (this.properties.getConfigurationProperties() != null) { factory.setConfigurationProperties(this.properties.getConfigurationProperties()); } if (!ObjectUtils.isEmpty(this.interceptors)) { factory.setPlugins(this.interceptors); } if (this.databaseIdProvider != null) { factory.setDatabaseIdProvider(this.databaseIdProvider); } if (StringUtils.hasLength(this.properties.getTypeAliasesPackage())) { factory.setTypeAliasesPackage(this.properties.getTypeAliasesPackage()); } if (this.properties.getTypeAliasesSuperType() != null) { factory.setTypeAliasesSuperType(this.properties.getTypeAliasesSuperType()); } if (StringUtils.hasLength(this.properties.getTypeHandlersPackage())) { factory.setTypeHandlersPackage(this.properties.getTypeHandlersPackage()); } if (!ObjectUtils.isEmpty(this.properties.resolveMapperLocations())) { factory.setMapperLocations(this.properties.resolveMapperLocations()); } return factory.getObject();} 结语通过上面分析mybatis如何集成springboot，知道了springboot入口在哪里以及如何实现的自动配置，这里只是简单的做了介绍，其中的一些源码和细节就没有分析了，我相信，入口知道了，接下来就好抠细节了。","link":"/2019/04/24/springboot/"},{"title":"springboot(六)——springboot与webflux结合初探","text":"spring-cloud-gateway 的ReactorHttpHandlerAdapter这几天看了看spring-cloud-gateway的请求处理流程，因为之前一直用的springboot1.x和spring4，一开始对spring-cloud-gateway的处理流程有点懵逼，找不到入口，后来跟了代码，在网上找了点资料，发现spring-cloud-gateway的入口在ReactorHttpHandlerAdapter的apply方法1234567891011121314151617181920212223242526272829303132333435public class ReactorHttpHandlerAdapter implements BiFunction&lt;HttpServerRequest, HttpServerResponse, Mono&lt;Void&gt;&gt; { private static final Log logger = HttpLogging.forLogName(ReactorHttpHandlerAdapter.class); private final HttpHandler httpHandler; public ReactorHttpHandlerAdapter(HttpHandler httpHandler) { Assert.notNull(httpHandler, \"HttpHandler must not be null\"); this.httpHandler = httpHandler; } @Override public Mono&lt;Void&gt; apply(HttpServerRequest reactorRequest, HttpServerResponse reactorResponse) { NettyDataBufferFactory bufferFactory = new NettyDataBufferFactory(reactorResponse.alloc()); try { ReactorServerHttpRequest request = new ReactorServerHttpRequest(reactorRequest, bufferFactory); ServerHttpResponse response = new ReactorServerHttpResponse(reactorResponse, bufferFactory); if (request.getMethod() == HttpMethod.HEAD) { response = new HttpHeadResponseDecorator(response); } return this.httpHandler.handle(request, response) .doOnError(ex -&gt; logger.trace(request.getLogPrefix() + \"Failed to complete: \" + ex.getMessage())) .doOnSuccess(aVoid -&gt; logger.trace(request.getLogPrefix() + \"Handling completed\")); } catch (URISyntaxException ex) { if (logger.isDebugEnabled()) { logger.debug(\"Failed to get request URI: \" + ex.getMessage()); } reactorResponse.status(HttpResponseStatus.BAD_REQUEST); return Mono.empty(); } }} 该方法的作用就是把接收到的HttpServerRequest或者最终需要返回的HttpServerResponse，包装转换为ReactorServerHttpRequest和ReactorServerHttpResponse。 spring-webflux当然，这篇文章的主要内容不是谈论spring-cloud-gateway了，因为之前一直用的spring4，所以对spring5当中的反应式编程范式和webflux不太了解，所以先写个demo了解一下第一步：引入相关pom,测试的相关pom根据自己的需要引入12345678910111213141516171819202122232425&lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.1.4.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt;&lt;/parent&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-webflux&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.projectreactor&lt;/groupId&gt; &lt;artifactId&gt;reactor-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 第二步：创建一个HandlerFunction12345678910111213public class TestFunction implements HandlerFunction&lt;ServerResponse&gt; { @Override public Mono&lt;ServerResponse&gt; handle(ServerRequest serverRequest) { return ServerResponse.ok().body( Mono.just(parse(serverRequest, \"args1\") + parse(serverRequest, \"args2\")) , Integer.class); } private int parse(final ServerRequest request, final String param) { return Integer.parseInt(request.queryParam(param).orElse(\"0\")); }} 第三步：注入一个RouterFunction12345678@Configurationpublic class TestRouteFunction { @Bean public RouterFunction&lt;ServerResponse&gt; routerFunction() { return RouterFunctions.route(RequestPredicates.GET(\"/add\"), new TestFunction()); }} 第四步：在webflux中，也可以使用之前的java注解的编程方式，我们也创建一个controller123456789@RestController@RequestMapping(\"/api/test\")public class HelloController { @RequestMapping(\"/hello\") public Mono&lt;String&gt; hello() { return Mono.just(\"hello world\"); }} 第五步：创建启动类1234567@SpringBootApplicationpublic class Spring5DemoApplication { public static void main(String[] args) { SpringApplication.run(Spring5DemoApplication.class, args); }} 第六步：启动项目，访问如下两个接口都可以12http://localhost:8080/api/test/hellohttp://localhost:8080/add?args1=2&amp;args2=3 和spring-boot结合通过上面的例子，我们看到基本的两个类：HandlerFunction和RouterFunction，同时webflux有如下特性： 异步非阻塞 响应式(reactive)函数编程，纯lambda表达式 不仅仅是在Servlet容器中tomcat/jetty中运行，同时支持NIO的Netty和Undertow中，实际项目中，我们往往与spring-boot项目结合，我们跟进代码可以看看spring-boot是在什么时候创建的server一、SpringApplication123456789101112131415161718192021222324252627282930313233343536373839404142434445public ConfigurableApplicationContext run(String... args) { StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); SpringApplicationRunListeners listeners = getRunListeners(args); listeners.starting(); try { ApplicationArguments applicationArguments = new DefaultApplicationArguments( args); ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); Banner printedBanner = printBanner(environment); context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances( SpringBootExceptionReporter.class, new Class[] { ConfigurableApplicationContext.class }, context); prepareContext(context, environment, listeners, applicationArguments, printedBanner); refreshContext(context); afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) { new StartupInfoLogger(this.mainApplicationClass) .logStarted(getApplicationLog(), stopWatch); } listeners.started(context); callRunners(context, applicationArguments); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); } try { listeners.running(context); } catch (Throwable ex) { handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); } return context;} 我们只分析入口，其它代码暂时不管，找到refreshContext(context);这一行进去 二、ReactiveWebServerApplicationContext的refresh()12345678910@Overridepublic final void refresh() throws BeansException, IllegalStateException { try { super.refresh(); } catch (RuntimeException ex) { stopAndReleaseReactiveWebServer(); throw ex; }} 三、ReactiveWebServerApplicationContext的onRefresh()1234567891011@Overrideprotected void onRefresh() { super.onRefresh(); try { createWebServer(); } catch (Throwable ex) { throw new ApplicationContextException(\"Unable to start reactive web server\", ex); }} 四、看到这里我们就找到入口方法了：createWebServer(),跟进去，找到NettyReactiveWebServerFactory中创建webserver1234567@Overridepublic WebServer getWebServer(HttpHandler httpHandler) { HttpServer httpServer = createHttpServer(); ReactorHttpHandlerAdapter handlerAdapter = new ReactorHttpHandlerAdapter( httpHandler); return new NettyWebServer(httpServer, handlerAdapter, this.lifecycleTimeout);} 看到ReactorHttpHandlerAdapter这个类想必特别亲切，在开篇说过是spring-cloud-gateway的入口，createHttpServer方法的细节暂时没有去学习了，后续有时间去深入了解下 结语spring5的相关新特性也是在学习中，这一篇文章算是和springboot结合的入门吧，后续有时间再深入学习","link":"/2019/05/05/springboot/"},{"title":"zookeeper的一篇概述","text":"之前在公司由于业务需要，对zookeeper进行了一些知识点的梳理进行分享，对一些刚刚接触zookeeper的小伙伴来说，或许可以借鉴一下 一、zookeeper介绍简介 Zookeeper致力于提供一个高性能、高可用，且具备严格的顺序访问控制能力的分布式协调服务。 设计目标 简单的数据结构:共享的树形结构，类似文件系统，存储于内存; 可以构建集群:避免单点故障，3-5台机器就可以组成集群，超过半数，正常工作就能对外提供服务; 顺序访问:对于每个写请求，zk会分配一个全局唯一的递增编号，利用 这个特性可以实现高级协调服务; 高性能:基于内存操作，服务于非事务请求，适用于读操作为主的业务 场景。3台zk集群能达到13w QPS; 应用场景 数据发布订阅 负载均衡 命名服务 Master选举 集群管理 配置管理 分布式队列 分布式锁 二、zookeeper特性会话(session):客户端与服务端的一次会话连接，本质是TCP长连接，通过会话可以进行心跳检测和数据传输; 数据节点(znode) 持久节点(PERSISTENT) 持久顺序节点(PERSISTENT_SEQUENTIAL) 临时节点(EPHEMERAL) 临时顺序节点(EPHEMERAL_SEQUENTIAL)对于持久节点和临时节点，同一个znode下，节点的名称是唯一的:[center red 20px] Watcher 事件监听器:客户端可以在节点上注册监听器，当特定的事件发生后，zk会通知到感兴趣的客户端。EventType: NodeCreated、NodeDeleted、NodeDataChanged、NodeChildrenChange ACL:Zk采用ACL(access control lists)策略来控制权限权限类型:create,read,write,delete,admin 三、zookeeper常用命令 启动ZK服务: bin/zkServer.sh start 查看ZK服务状态:bin/zkServer.sh status 停止ZK服务: bin/zkServer.sh stop 重启ZK服务: bin/zkServer.sh restart 客户端连接：zkCli.sh -server 127.0.0.1:2181 显示目录：ls / 创建：create /zk “test” 获得值：get /zk 修改值：set /zk “test” 删除：delete /zk ACL: getAcl / setAcl addauth 四、zookeeper的java客户端12345678910&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-framework&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.apache.curator&lt;/groupId&gt; &lt;artifactId&gt;curator-recipes&lt;/artifactId&gt; &lt;version&gt;2.12.0&lt;/version&gt; &lt;/dependency&gt; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public class App { public static void main(String[] args) throws Exception { String connectString = \"211.159.174.226:2181\"; RetryPolicy retryPolicy = getRetryPolicy(); CuratorFramework client = CuratorFrameworkFactory.newClient(connectString, 5000, 5000, retryPolicy); client.start(); //增删改查 client.create().withMode(CreateMode.PERSISTENT).forPath(\"/test-Curator-PERSISTENT-nodata\"); client.create().withMode(CreateMode.PERSISTENT).forPath(\"/test-Curator-PERSISTENT-data\", \"test-Curator-PERSISTENT-data\".getBytes()); client.create().withMode(CreateMode.EPHEMERAL).forPath(\"/test-Curator-EPHEMERAL-nodata\"); client.create().withMode(CreateMode.EPHEMERAL).forPath(\"/test-Curator-EPHEMERAL-data\", \"/test-Curator-EPHEMERAL-data\".getBytes()); for (int i = 0; i &lt; 5; i++) { client.create().withMode(CreateMode.PERSISTENT_SEQUENTIAL).forPath(\"/test-Curator-PERSISTENT_SEQUENTIAL-nodata\"); } byte[] bytes = client.getData().forPath(\"/test-Curator-PERSISTENT-data\"); System.out.println(\"----------zk节点数据:\" + new String(bytes) + \"------------\"); client.create().withMode(CreateMode.PERSISTENT).forPath(\"/test-listener\", \"test-listener\".getBytes()); final NodeCache nodeCache = new NodeCache(client, \"/test-listener\"); nodeCache.start(); NodeCacheListener listener = new NodeCacheListener() { @Override public void nodeChanged() throws Exception { System.out.println(\"node changed : \" + nodeCache.getCurrentData()); } }; nodeCache.getListenable().addListener(listener); client.setData().forPath(\"/test-listener\", \"/test-listener-change\".getBytes()); } /** * RetryOneTime: 只重连一次. * RetryNTime: 指定重连的次数N. * RetryUtilElapsed: 指定最大重连超时时间和重连时间间隔,间歇性重连直到超时或者链接成功. * ExponentialBackoffRetry: 基于\"backoff\"方式重连,和RetryUtilElapsed的区别是重连的时间间隔是动态的 * BoundedExponentialBackoffRetry: 同ExponentialBackoffRetry,增加了最大重试次数的控制. */ public static RetryPolicy getRetryPolicy() { return new ExponentialBackoffRetry(1000, 3); }} 五、分布式锁123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public class ZookeeperLock { private final String lockPath = \"/distributed-lock\"; private String connectString; private RetryPolicy retry; private CuratorFramework client; private InterProcessLock interProcessMutex; public void init() throws Exception { connectString = \"211.159.174.226:2181\"; retry = new ExponentialBackoffRetry(1000, 3); client = CuratorFrameworkFactory.newClient(connectString, 60000, 15000, retry); client.start(); //共享可重入锁 interProcessMutex = new InterProcessMutex(client,lockPath); } public void lock(){ try { interProcessMutex.acquire(); } catch (Exception e) { System.out.println(\"锁失败了,真惨\"); } } public void unlock(){ try { interProcessMutex.release(); } catch (Exception e) { System.out.println(\"释放失败了，更惨\"); } } public static void main(String[] args) throws Exception { final ZookeeperLock zookeeperLock = new ZookeeperLock(); zookeeperLock.init(); Executor executor = Executors.newFixedThreadPool(5); for (int i = 0;i&lt;50;i++) { executor.execute(new Runnable() { @Override public void run() { zookeeperLock.lock(); Long time = System.nanoTime(); System.out.println(time); try { Thread.sleep(1000); } catch (InterruptedException e) { e.printStackTrace(); } System.out.println(time); zookeeperLock.unlock(); } }); } while (true){ } }} 六、zab协议 ZAB协议所定义的三种节点状态 Looking ：选举状态。 Following ：Follower节点（从节点）所处的状态。 Leading ：Leader节点（主节点）所处状态。 Zxid(64位的数据结构)前32位：Leader 周期编号 myid低32位：事务的自增序列（单调递增的序列）只要客户端有请求，就+1当产生新Leader的时候，就从这个Leader服务器上取出本地log中最大事务zxid，从里面读出epoch+1，作为一个新epoch，并将低32位置0（保证id绝对自增）。 崩溃恢复 每个server都有一张选票&lt;myid，zxid&gt;，选票投自己。 搜集各个服务器的投票。 比较投票，比较逻辑：优先比较zxid，然后才比较myid。 改变服务器状态（崩溃恢复=》数据同步，或者崩溃恢复=》消息广播） 消息广播(类似2P提交)： Leader接受请求后，讲这个请求赋予全局的唯一64位自增Id（zxid）。 将zxid作为议案发给所有follower。 所有的follower接受到议案后，想将议案写入硬盘后，马上回复Leader一个ACK（OK）。 当Leader接受到合法数量Acks，Leader给所有follower发送commit命令。 follower执行commit命令。 PS::到了这个阶段，ZK集群才正式对外提供服务，并且Leader可以进行消息广播，如果有新节点加入，还需要进行同步。","link":"/2019/08/11/zookeeper/"}],"tags":[],"categories":[{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"redis","slug":"redis","link":"/categories/redis/"},{"name":"springboot","slug":"springboot","link":"/categories/springboot/"},{"name":"go","slug":"go","link":"/categories/go/"},{"name":"springcloud","slug":"springcloud","link":"/categories/springcloud/"},{"name":"java杂事","slug":"java杂事","link":"/categories/java杂事/"},{"name":"git","slug":"git","link":"/categories/git/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/categories/elasticsearch/"},{"name":"schedule","slug":"schedule","link":"/categories/schedule/"},{"name":"zookeeper","slug":"zookeeper","link":"/categories/zookeeper/"}]}